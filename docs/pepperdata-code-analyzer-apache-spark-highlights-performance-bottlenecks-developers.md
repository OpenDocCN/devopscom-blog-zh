# Apache Spark 的 Pepperdata 代码分析器强调了开发人员的性能瓶颈

> 原文：<https://devops.com/pepperdata-code-analyzer-apache-spark-highlights-performance-bottlenecks-developers/>

> *New product identification leads to problems with CPU, memory, garbage collection, network and disk I/ O Code lines and phases of related performance problems*
> 
> **Cupertino, California- May 23, 2017 -** [](http://www.pepperdata.com/?utm_medium=pr&utm_source=kulesa_faul&utm_campaign=17q1_application_profiler)**Perdata 【T20] today announced the [PepperData code analyzer for Apache Spark, which enables Spark application developers to identify performance problems and associate them with specific code blocks in their applications. Code Analyzer is a new product following](https://www.pepperdata.com//products/code_analyzer/) [](http://www.pepperdata.com/pr_030717/)[Pepperdata Application Analyzer](http://www.pepperdata.com/pr_030717/) , which provides practical suggestions for Hadoop and Spark developers to improve their work performance.**
> 
>  **"One of the biggest challenges facing big data is to achieve the best performance," said Ash Munshi, CEO of Pepperdata. "Code Analyzer fills a huge gap in Spark application development and helps developers optimize Spark applications for mass production. Now, developers can use new information and insights around the code, build, test and release stages to improve the performance of Spark applications. "
> 
> The performance index of Spark Web UI is always a challenge for developers to understand, especially when there is no granular time series data on hand. It's not easy for developers to get a deep understanding of the problematic parts of the application that need to be optimized. In addition, since Spark clusters usually run many applications in parallel, Spark Web UI will not inform developers how applications are affected by other applications running on the cluster.
> 
> Pepper Data Code Analyzer allows Spark application developers to accurately measure how any specific application code block consumes cluster resources, including CPU, memory, network and disk I/O. Code Analyzer provides additional insight by combining application information of Spark engine with granular time series data of all applications running on the cluster. Development teams have the ability to identify the specific parts of their application code that are responsible for performance problems.
> 
> "I developed a lot of complicated Spark code to execute ETL on Hadoop cluster. In these complex large-scale systems, you must be able to understand where the performance bottleneck lies, "said Ian O'Connell, a software engineer and member of Stripe and Pepperdata technical advisory committee. "Pepperdata code analyzer for Apache Spark provides developers with detailed sequential performance data, including CPU, JVM memory and I/O usage, and Spark job phase. I'm excited about the development direction of Pepperdata-let developers quickly see the problems in the time series view and connect them with the actual Spark application code, which will be a very useful tool for developers developing and producing Spark applications. "
> 
> **The benefits of the code analyzer include:**
> 
> *For developers:*
> 
>  ● Determine which lines of code and which phases will lead to problems with CPU, memory, garbage collection, network and disk I. O Related performance problems
> 
>  ● Easily distinguish the resources used in the parallel phase
> 
>  ● Understand why the running time of the same application changes
> 
>  *caused by other workloads is OPS:*
> 
>  ● Reduce the number of performance accidents in production
> 
>  ● Easily put the detailed performance Chartboost uses Apache Spark on a large Amazon EC2 Hadoop cluster for machine learning and ET L workflow, "said Michael McGowan, data engineering manager of Chartboost. "Understanding the performance of Spark applications in these complex environments is always a challenge. As the current user of Pepperdata Hadoop performance management tool, it is a great thing to cooperate with Pepperdata to develop code analyzer. It will give us a comprehensive understanding of Spark jobs. "
> 
> Pepperdata products and services are designed to accelerate the production and use of big data applications by ensuring the tight integration of performance into the development and operation of big data cycle. Code Analyzer is integrated with [](http://www.pepperdata.com/products/)[Pepperdata product](http://www.pepperdata.com/products/) , providing an end-to-end DevOps solution, combining the overall cluster awareness (monitoring, troubleshooting and alarm) with in-depth suggestions to improve the performance of individual jobs.
> 
> **Supply and pricing**
> 
>  The code analyzer for Apache Spark will be listed on June 5th , and it is expected that it will be officially listed in the third quarter of 2017\. Pepperdata products are put on the market as software combinations and SaaS solutions running in customer clusters, in-house or in the cloud. Please contact [[email protected]](/cdn-cgi/l/email-protection#7201131e170132021702021700161306135c111d1f) for pricing information or to arrange a demonstration. **T9]**
> 
> **Useful links**
> 
>  ● [Pepperdata website](http://pepperdata.com/?utm_medium=pr&utm_source=kulesa_faul&utm_campaign=17q1_application_profiler)
> 
>  T11] Pepperdata code analyzer
> 
>  ● [Pepperdata application analyzer](http://www.pepperdata.com/products/application-profiler?utm_medium=pr&utm_source=kulesa_faul&utm_campaign=17q1_application_profiler)
> 
>  ● [T12 2] Blog
> 
>  ● [Twitter](https://twitter.com/pepperdata?utm_medium=pr&utm_source=kulesa_faul&utm_campaign=17q1_application_profiler) T3]
> 
>  ● [LinkedIn](https://www.linkedin.com/company/pepperdata?utm_medium=pr&utm_source=kulesa_faul&utm_campaign=17q1_application_profiler)
> 
> [[Email protection]](/cdn-cgi/l/email-protection) Continue to release Apache code analyzer # Spark [http://ow.ly/ <wbr> 1OXS30BT1SG ](http://ow.ly/1oxS30bT1sg) # devops # Big Data **About Pepperdata T3]**
> 
>  Pepperdata is the DevOps of big data companies. Leading companies such as Comcast, Philips Wellcentive and Zillow rely on Pepperdata to manage and improve the performance of Hadoop and Spark. Enterprise developers and operators use Pepperdata products and services to diagnose and solve performance problems in production and improve cluster utilization. Pepperdata product suite improves the communication between developers and operators on performance issues, shortens the production time, and improves the return on investment of clusters. Pepperdata products and services work with customers' internal and big data systems in the cloud.
> 
>  PepperData was founded in 2012\. It has raised USD 20 million from investors including Citi Ventures, Signia Venture Partners and Wing Venture Capital, and attracted senior engineering talents from Yahoo, Google, Microsoft and Netflix. Pepperdata is headquartered in Cupertino, California**

**— [帕克·耶茨](https://devops.com/author/parkerdevops-com/)**