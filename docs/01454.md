# 重复数据删除解决方案对 Cassandra 有用吗？

> 原文：<https://devops.com/will-deduplication-solutions-work-cassandra/>

Cassandra 是一个流行的下一代数据库系统(NoSQL ),为企业中高性能网络规模应用的后端提供支持。正是面向云应用程序的数据库软件提高了组织为越来越多需要跨数据中心和云分发数据的云应用程序提供支持的能力。

虽然 Cassandra 提供了高可用性，但它也为满足数据保护要求提供了重要机会。创建分布式数据库的群集一致且节省空间的备份可能是一项具有挑战性的任务。在这篇博文中，我将重点介绍 Cassandra 现有的重复数据删除解决方案，为什么重复数据删除很重要，以及如何在 Cassandra 中实现重复数据删除。

## 卡珊德拉是什么？

下面简单介绍一下。您可能会好奇，“现有的重复数据删除解决方案不足以节省 Cassandra 快照文件的空间吗？”有多种重复数据消除解决方案可以消除存储层不同级别的冗余数据。那么，为什么我们需要一个新的 Cassandra 集群备份呢？

让我们从一些背景信息开始。

Cassandra 是一个分布式数据库，随着软件即服务(SaaS)、物联网(IoT)和实时分析等大数据应用的出现，它变得越来越受欢迎。这些应用程序需要高可用性和可伸缩性，而不是一致性。Cassandra 支持最终一致性而不是严格一致性，后者由 Oracle、MySQL 和 IBM DB2 等传统数据库系统提供。“最终一致”意味着一致性将最终实现，而不是立即实现。众所周知，在 CAP 定理中，我们不能在一个系统中同时拥有以下三个属性:一致性、可用性和分区容差。简而言之，Cassandra 是一个最终一致的数据库，它提供了高性能、高可用性和高可伸缩性——但不是强一致性。

## 复制及其在重复数据消除中的作用

Cassandra 等分布式横向扩展数据库系统的最重要机制之一是数据复制。通过跨故障边界在不同节点上复制相同的数据，分布式数据库系统可以继续服务于应用程序请求，即使有一定数量的节点故障。缺点是维护多个数据副本的性能开销；创建多个副本和检查多个副本之间的一致性时，写入和读取操作都会变慢。虽然异步数据复制技术可以用来最小化写操作的性能开销，但是它也会降低保证的一致性水平，即最终一致性。

正如我刚才解释的，复制在分布式数据库系统中起着非常重要的作用，因此我们不应该为了节省存储空间而从一个活动的 Cassandra 集群中删除冗余。

当我们考虑 Cassandra 集群中的备份文件(或二级数据)时，情况就不同了。像企业组织中的任何其他数据库系统一样，Cassandra 需要备份；这并不是因为 Cassandra 不可靠或不够可用，主要是因为人们会犯错误(“胖手指”)，企业应用程序有时必须保留其数据库的历史。正如他们所说，人非圣贤孰能无过！

Cassandra 有一个很好的节点级快照特性，可以将单个节点的完整状态保存到快照文件中。非常重要的一点是，Cassandra 快照是一种“按节点”操作，它不能保证有关群集状态的任何事情，如下图所示。

![1](img/04d6194315a504e357f4c9f007d7f769.png)

## 备份 Cassandra 集群

要创建 Cassandra 集群的备份，我们必须在每个节点上触发快照操作，收集创建的快照文件，然后将收集的快照文件集作为备份。在此备份中，复制的数据按原样存在，备份的大小将比用户数据的大小大 N 倍，其中“N”是复制因子。复制在“实时”Cassandra 集群中有着重要的作用，可以提供高可用性和可伸缩性，但是复制对备份有什么用呢？如果我们将备份文件上传到 S3 或 Swift 等对象存储，对象存储将再次复制“已复制”的数据，以提供可靠性和可用性。简而言之，Cassandra 备份文件中存在冗余数据副本(次要数据)。如果我们能够消除冗余数据副本，我们将为 Cassandra 备份节省大量存储空间，而不会牺牲保留期。节省存储空间直接转化为节省维护和运营整个组织的大数据系统的运营成本。

但是，让我们回到现有的重复数据删除解决方案是否适用于 Cassandra 备份文件的问题。您可以通过收集 Cassandra 数据库文件并将其放入重复数据删除系统来测试这一点。该解决方案能否节省存储消耗？不要！现有的重复数据删除解决方案不适用于 Cassandra 数据文件，原因如下:

*   卡珊德拉有一个无主的对等架构。每个节点接收一组不同的行，因此群集中没有完全相同的节点，这意味着数据文件看起来会有所不同，如下图所示。由于不同的行组合存储在 Cassandra 数据文件中，即使在块级别，每个数据文件也很难完全相同。![2](img/f0a9da204696a10bc6a7cd0ab37b8185.png)
*   Cassandra 数据文件以 64KB 大小的块进行压缩，不考虑行边界。如果您对重复数据删除算法有足够的了解，您就很容易理解为什么 Cassandra 数据文件不能轻松地进行重复数据删除。固定长度、基于区块的重复数据消除因区块对齐而无法工作，可变长度、基于区块的重复数据消除因压缩而无法工作。

Cassandra 的压缩和较小的记录大小是现有数据块级或文件级重复数据消除解决方案不适用于 Cassandra 备份文件的其他原因。压缩是将多个数据库文件合并成一个新数据文件的独立操作；小型记录很难与大型区块一起进行重复数据消除。

## 摘要

现有的文件级和数据块级重复数据消除解决方案不适用于 Cassandra 备份文件，因为:

1.  每个 Cassandra 数据文件包含不同的记录集。
2.  不管行边界如何，Cassandra 数据文件都会被压缩。
3.  卡珊德拉独立经营契约。
4.  Cassandra 的记录大小可以小于重复数据删除区块大小。