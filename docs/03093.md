# 我们仍然没有解决伐木问题

> 原文:[https://devo PS . com/we-仍然没有解决日志问题/](https://devops.com/we-still-havent-solved-the-logging-problem/)

在我之前工作的一家公司，我帮助构建了初始基础设施，以支持一个大型云安全产品。这是我第一次有机会几乎从最开始就开始构建一些东西。像许多运营专业人士一样，在这次经历之前，我职业生涯中的大部分时间都花在了清理他人的烂摊子和技术债务上，以至于我最终从一开始就对“做正确的事情”感到兴奋。

回顾过去，我希望我知道，如果没有保留和分析热和冷日志数据的能力，构建我们的监控平台将会受到阻碍。原因如下。

## **时间序列** **到**

后见之明几乎总是 20/20，今天我可以自豪地说，我和我的团队构建了一个杀手级的 app 监控平台。我的目标是让开发和运营人员能够轻松报告他们的应用程序的时间序列指标，并为应用程序运行状况构建仪表板和警报。我们做到了。

虽然许多运营部门的同事会说，监控之旅通常是从使用 Logstash/Elasticsearch、Graylog2 等开源工具捕获应用程序日志开始的，甚至是从 Splunk 或 Sumo Logic 购买商业服务，但并不是所有的旅程都是这样开始的。我和我的团队采取了不同的方法，针对时间序列指标进行了优化，而不是更传统的结构化日志管理方法，利用更新的工具集，如进行实时运营监控和性能分析。Librato 使我们能够以比传统日志解决方案更快的速度进行扩展，并让我们几乎可以即时了解我们的容器、云服务器和应用程序本身。

## **伐木太贵**

使用 Librato 这样的托管服务来管理我们的时间序列指标在一段时间内运行良好。然而，SaaS 监控的成本最终增加了，而且，由于我们有时间和精力在内部引入指标，我们部署了开源企业级监控工具[【Graphite】](https://graphiteapp.org/)。Graphite 使我们能够继续让我们的工程师以合理的价格访问粒度时间序列指标，帮助他们管理应用。

虽然这允许业务在出现问题时快速响应，但时间序列指标只是解决方案的一部分。他们允许我们看到正在发生的事情，但并不总是 T2 为什么会发生。虽然时间序列指标，甚至一些更先进的跟踪技术，包括 [Jaeger](https://www.jaegertracing.io/) 和 [Opentracing](http://opentracing.io/) 对于帮助调试复杂的分布式系统来说是非常棒的，但在调查和分析问题、问题和黑客攻击的原因时，它们是不够的。

## **挖掘你的日志历史变得昂贵，快**

ELK stack 等工具一直在蓬勃发展，仅 Elastic 去年就达到了超过 [1 亿次下载](https://www.elastic.co/about/press/elastic-reaches-100-million-downloads-for-the-elastic-stack) ，这表明 DevOps 团队希望从传统的日志管理解决方案中获得更多。他们寻求简单性、易用性和经济性等。由于 JSON 实际上是日志记录的标准，大多数团队使用预定义的模式获取日志数据，然后将其索引到 Elasticsearch/Lucene 中。不幸的是，Lucene 索引机制导致了一个意想不到的后果:磁盘使用量 增加了 [5 到 10 倍。就这样，当 ops 云预算意识到索引到 Elasticsearch 中的 10GB JSON 数据可能会占用 50GB 的磁盘空间时，他们会大吃一惊。您还希望复制该索引用于灾难恢复吗？然后为每 10GB 的日志添加 100GB 的存储。](https://stackoverflow.com/questions/27972246/elasticsearch-index-much-larger-than-the-actual-size-of-the-logs-it-indexed)

## **DevOps Normal:在保留和成本之间仍然是艰难的选择**

不幸的是，大多数人选择尽快从我们的“热门”弹性搜索集群中清除数据，以尽量减少成本问题。这远非理想。

迁移到部署在 Kubernetes 等容器上的基于微服务的架构的公司，当他们开始构建他们的集中式日志记录平台以跟上数量时，将会猛然惊醒。安全团队也将感受到这一负担，因为出于合规性和审计原因，他们在长期保留数据方面面临越来越大的压力。当下一个面向 web 的大漏洞出现时，回溯几周或几个月的能力将是查看哪个 IP 地址访问了潜在的恶意端点的关键。有了这些可用的数据，我们就可以将所有这些 IP 与其他访问日志关联起来。

集中式日志记录比 10 年前好吗？或者所有这些生成的数据爆炸式增长，以至于我们今天拥有的工具只能勉强跟上？有一点是肯定的，这个问题远远没有解决，许多公司可能会发现自己淹没在自己的数据湖中。

彼得·切斯洛克