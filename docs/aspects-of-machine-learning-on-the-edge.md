# 边缘机器学习的方方面面

> 原文：<https://devops.com/aspects-of-machine-learning-on-the-edge/>

机器学习(ML)很难。让它在嵌入式设备的有限环境中工作很容易成为一个泥潭，除非我们考虑并经常重新审视受 ML 要求关键影响的设计和部署方面。一点前期规划决定了项目的成败。

对于本文，我们的重点是用重要的，甚至是占主导地位的 ML 组件构建商业级应用程序。边缘设备，尤其是支持 ML 的设备，不会孤立运行；它们只是复杂自动化管道中的一个元素。

你有一个设备，或者更好的是，一个可以执行复杂分析的想法，通常是接近实时的，并提供网络流量、用户数据显示、机器控制或所有三者的结果。在设计过程中你越早，你就能越好地调整你的硬件和软件栈来满足 ML 的要求。可用的工具(尤其是在边缘)既不成熟，也不通用。你越灵活，构建可行产品的几率就越大。

让我们从描述一个假设的器件开始，然后我们将讨论设计的一些 ML 考虑因素。当我们讨论设计时，我们将访问和重新访问与这些其他工程流程齐头并进的 DevOps 自动化。

## **智能安全摄像头**

对于我们的设计，让我们来看一个网络安全摄像机。作为物联网设备，它持续连接到互联网。我们假设我们的设备将至少有 4GB 的 SDRAM，一个 64 位 ARM CPU，并运行一个嵌入式 Linux，支持 [Anaconda](https://www.anaconda.com/) Python 发行版、 [OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_setup/py_table_of_contents_setup/py_table_of_contents_setup.html) 、 [DLIB](http://dlib.net/python/index.html) 和 [TensorFlow](https://www.tensorflow.org/) 。

我们的 ML 相关目标首先是记录和标记感兴趣的帧，其次是提醒安全人员注意可疑活动。我们受到各种物理、环境和成本因素的制约。为了充分利用可用数据，我们需要使用 ML 来检查和分类每个图像帧中的多个对象。我们将使用云服务来处理第二个目标，所以在这里，边缘的 ML 涉及图像识别。我们应该如何进行？

## **在云端处理图片？**

我们需要识别画面中的各种物体，比如人、脸、车辆等等。每个对象集需要 ML 模型的执行([推理](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/))，这产生一组有界的、带标签的对象。一台典型的照相机每秒钟可以记录大约 30 帧。我们的相机不能把数据发送给云提供商吗？忽略其他考虑，这大约是 250 万张图片/天；即使有很大的折扣，每天也要收费 1000 美元，这是针对每个应用的识别模型的。显然，我们需要做出其他选择。

让我们从检查原始输入流开始。每个 raw [720p(标准 HD 1280x720px)](https://en.wikipedia.org/wiki/720p) 帧使用大约 5MB，因此如果我们要通过网络发送 30 帧/秒，我们将需要难以置信的 1.5Gbps 连接(大约每两小时一 TB)。对于全高清和更高的，乘以 4 到 10 倍。我们不会发送原始的，未压缩的视频。我们的问题是我们的最大似然模型只能对单个图像帧起作用。我们应该在哪里做出取舍？

视频产生了大量的数据，但是在给定的帧中很少有新的信息；这就是为什么各种压缩技术工作得非常好，原始数据缩减 100-1000 倍是典型的。这些降低到 1.5 Mbps 的速率是相当合理的，所以也许我们可以使用云服务来进行 ML 推断，只要我们托管自己的机器实例，而不是为 ML 服务付费。根据我们的工作负载，我们预计可以处理 24×7 视频，每月50 到 200 美元。

已经决定在云中托管我们的 ML 模型，我们现在需要管理一组相应的 DevOps 考虑事项。我们有足够的计算能力来管理服务吗？随着边缘机器数量的增加，我们将如何扩展工作负载？什么是存储和数据保留策略？当然，由于我们处理的是人的图像，我们将如何管理隐私问题以及相关的法律和政治分歧。

什么会让我们偏向更多的云处理？

*   我们最初的开发预算更加有限。
*   我们的 ML 模型在有限的处理/内存环境中尚未被证明是有效的。
*   我们需要灵活地快速改变我们用于处理的模型。
*   我们知道网络连接是健壮的，并且不需要离线操作。
*   我们的云服务预算可能会大大超过我们的边缘硬件成本。

在云中处理还是在边缘处理之间的选择不是二元的。即使是有限的边缘计算也能让设计受益匪浅；在某些情况下，可以在边缘实施简单的检测(运动/车辆/人/脸),以将云工作负载减少几个数量级，而不会损失效用。

## 我们能在边缘完成大部分工作吗？

如果我们在我们的四核 ARM 上使用带有 C 库加速的 Python，简单的 ML 模型，如[人脸检测](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html)(不是[识别](https://arxiv.org/pdf/1804.06655.pdf))可能每秒处理 10 到 20 帧，但在类似全尺寸图像的任何东西上每秒 30 帧是不可能的。更深、更复杂的模型不适合我们有限的内存，如果它们适合，我们可以看到每帧推理时间超过一秒。我们现在面临着边缘生活的现实:权衡取舍。

一旦我们承诺将我们的模型放入边缘设备，我们将需要持续集成(CI)和部署服务来支持我们的产品。这将使我们能够在云中训练和重新训练我们的模型，自动化验证改进的过程，并生成嵌入式代码来更新我们目标设备中的模型。

由于我们最初使用了非常适合基于 GPU 的服务器的模型，我们可以只在我们的设备上添加一个 GPU 吗？一句话，是的，但有一些非常真实的成本。采用具有 GPU 支持的替代 SoM 将提供推理性能的大量改进，但是将使单位成本增加一倍或三倍，并且功耗将增加。此类变更可能导致重大的非重复性工程，因为需要对模型进行调整、重写或重新培训，以利用新硬件。非重复性工程是与零件、组件或系统变更相关的一次性成本。

在某些情况下，我们可以将一个[英特尔 Movidius 神经计算棒](https://software.intel.com/en-us/neural-compute-stick) (NCS)插入一个备用 USB 端口，并看到每张图像的速率提高了 5 到 10 倍。这些都是由[英特尔 OpenVINO toolkit](https://software.intel.com/en-us/openvino-toolkit) 支持的，但是需要一些开发时间来运行，并且不是每个模型都可以工作。

盒子里的下一个工具是现场可编程门阵列(FPGA)开发。将这些纳入我们的主板设计是一件苦差事，但性能可以等于或优于 GPU(在某些型号上)，功耗更低。英特尔 OpenVINO 工具包支持用于 DNNs 的 [Arria](https://www.intel.com/content/www/us/en/products/programmable/arria-series.html) 和[Stratix](https://www.intel.com/content/www/us/en/products/programmable/stratix-series.html)FPGA。价格可能会令人望而却步。

最后，如果我们的设备将被大量生产，它可以价值几百万美元的 NRE，以建立一个专用集成电路(ASIC)。ASIC 设计的沉没成本可能是巨大的，但较低的单位成本将弥补这一点。只有当我们的设计得到验证、锁定，并且我们确信市场能够承受在这些工程成本上实现收支平衡所需的销量时，我们才会走这条路。我应该注意到 ASICs 中 dnn 数据流处理的架构改进，如 [Vivienne Sze 的作品](http://navion.mit.edu/)，显示了重量、功耗和成本大幅改善的前景。如果你打算长期发展，不要排除这些发展。

什么会使我们的边缘处理更容易？

*   先从小尺寸的型号开始，如 [TinyYOLO](https://github.com/simo23/tinyYOLOv2) 、 [MobileNet](https://github.com/d-li14/mobilenetv3.pytorch) 或 [SqueezeNet](https://github.com/DeepScale/SqueezeNet) 。
*   在我们的设计中，接受较低的图像处理帧速率。
*   预先考虑硬件细节和工具集，评估 ML 模型。
*   提供自动化开发运维服务来更新您设备中的模型。

构建在边缘设备上运行的 ML 模型将涉及大量的开发成本。工具链不能无缝安装，通常需要花费几天到几周的时间来调整环境。与我们在 DevOps 环境中所习惯的相比，在这些平台上的开发和测试往往更慢，并且涉及更多的手动步骤。

在边缘上运行模型会增加我们的 DevOps 复杂度。我们的云工作负载将会降低，但现在我们将包括交叉编译、嵌入式代码构建、更大图像的下载管理以及各种额外的测试和验证阶段。除此之外，我们还需要为纯云系统解决培训、负载平衡、数据保留、隐私和安全问题。

## **结论**

还有什么会影响我们在这里的选择？投入的性质真的很重要。如果我们的相机将繁忙道路上的交通或机场候机楼里的人们可视化，我们可以预期几乎每一帧都会包含一些有趣的东西；如果我们监控的是停车场的底层，就没那么多了。

概括一下:

*   视频速率 ML 的云服务成本过高。
*   尽早整合 DevOps，以完善您的产品支持系统。
*   根据数量、规模和重要性理解和描述您的输入数据。
*   认识到不是每个模型都可以在边缘硬件上执行。
*   您在边缘硬件方面的选择比您想象的要多。

尽管在设备中构建更多智能仍然存在挑战，但重要的是要认识到这些限制每年都在减少，工具越来越好，设备越来越强大。一个令人信服的论点是，大多数数据处理应该尽可能地靠近其来源。

约翰·福格蒂