# 不带刻度的 DevOps，第 2 部分

> 原文:[https://devops.com/devops-without-scale-part-2/](https://devops.com/devops-without-scale-part-2/)

在本系列的第 1 部分中，我介绍了了解产品健康状况的重要性以及如何做到这一点。我介绍了用户体验和度量的技术类型，以及如何开始收集它们。在本系列的这一部分，我将带您了解如何使用所有这些指标来最大化用户体验和产品正常运行时间。

## 指标，无处不在的指标

这里没有灵丹妙药，你必须持续关注产品的健康状况，以及它与用户期望的差距。这当然需要时间和努力，但它是构建一个好产品的重要部分。想象一下，如果椅子设计师不关心人们如何使用他们的作品；那些椅子坐起来会不舒服。同样，理解用户需求对任何软件工程师来说都是至关重要的。

一旦你对你的应用程序模式有了基本的理解，你还没有完成。每一次发布都是引入更多延迟或故障的机会，并且基线是不断变化的。很容易显著影响延迟，也很容易打破边缘情况，并使任何版本的用户故障增加几个百分点。确保高质量用户体验的唯一方法是时刻了解产品的健康状况和用户的期望。

在这种情况下，越少越好，用户更喜欢能够工作且响应迅速的功能。试试看，看看你的用户怎么说！

### 用户体验监控

良好用户体验的第一部分是低错误率。对于 web 产品，这些包括所有 http 错误响应以及返回给用户的所有应用程序错误。对于 API 和 GUI，这包括应用程序故障(以及 REST APIs 的 http 错误)。我听到的一个反复出现的评论是，用户提交无效的输入，这总是会导致错误响应，所以它不应该被计算在内。能够区分硬故障和糟糕的用户输入当然是有用的，但是界限比你想象的更模糊。例如，一个新的版本可能会改变输入期望，而以前有效的请求可能会出错。这是糟糕的用户输入还是你破坏了你的产品？

在这两种情况下，如果失败次数很高，用户会不高兴，你需要处理这个问题。这里的解决方案可能是非技术性的:也许您需要更好的文档或用户培训，或者也许 API 或 UX 设计很麻烦，导致误解和误用。不管是什么情况，都必须解决。用户很可能会放弃一个笨重的产品，就像放弃一个不起作用的产品一样。

与其他任何事情一样，我建议您确定产品的一些高级和最重要的部分，并跟踪这些指标。如果您确实注意到了一个问题，那么您手头上就有了更详细的指标来进行深入研究。

良好用户体验的另一部分是性能，这里的方法也不例外。通常，您需要在跟踪故障时跟踪相同用户操作的延迟。性能跟踪是您真正需要了解什么是可接受的，什么是不可接受的，这取决于领域和您的用户的期望。在公共旅游网站上，两秒钟打开一个预订似乎是很长的时间，但两秒钟调出一个金融公司内部用户的贷款记录就不错了。

要记住的一个重要事实是，系统中总会有一些故障，这很正常。不管你的产品有多棒，文档有多清晰，你和你的用户有多合拍，总会有一些失败是由糟糕的用户交互造成的。在某种程度上，一旦你对你的产品总体感觉良好，你将不得不假设给定的错误率是你的基线。然后，你需要注意随时间的变化，每隔一段时间就批判性地重新审视。

### 预测监控

除了用户体验指标之外，还有值得关注的关键技术指标，因为它们可以指出即将出现的问题。一些常见的是 CPU 和内存利用率、线程和数据库池大小、虚拟机堆大小和垃圾收集时间。就像用户度量一样，您需要知道您的应用程序的操作签名。但是除此之外，您需要理解这些指标的变化如何影响您的用户，如果有的话。

不断增长的线程池可能意味着响应时间变慢，也可能仅仅意味着更多的用户正在访问您的服务。不断增长的电子邮件队列意味着电子邮件发送的速度变慢了，但这是坏事吗？只有了解你的领域和用户，才会给你答案。如果 CPU 徘徊在 80 %,一切都很好——就目前而言，但你需要迅速扩大规模，以免流量的微小增加破坏整个应用程序。

在跟踪硬件指标时，每个人都密切关注过度利用，因为这是导致停机的原因。但是利用不足呢？性能上下波动，有时您会发现自己没有充分利用资源。注意这一点是保持节俭和控制成本的好方法。

### 发信号

你怎么知道什么时候东西坏了？你不能整天盯着图表。一旦您对系统的正常特征有了感觉，您就可以创建自动化的监视器和警报了。自动报警最重要的一点是它必须始终值得信赖。当你和你的团队开始收到假警报的时候，每个人都将学会忽略其中的一些，系统的价值将会直线下降。因此，我建议您只对几个最关键的指标启动自动警报。运行整个系统几个星期，并随着时间的推移慢慢增加更多的指标。

设置自动警报时需要注意的另一个方面是指标随时间的变化，最常见的是白天与夜晚。没有人希望因为凌晨 3 点流量太低而被寻呼。同时，如果您的指标飙升或突然下降，这可能是一个令人担忧的原因。你是被扔了还是被刮了？是否存在网络故障，导致无法访问您的服务？

为了解决这个问题， [DataDog](https://www.datadoghq.com/) 具有内置的报警功能，称为监视器。它们提供了一些不同的方法来确保没有误报。例如，您可以创建一个仅在增量上触发的更改警报，而不是设置绝对阈值。添加新显示器只需几分钟。

最后，当警报响起时，需要有人被呼出来。DataDog 可以发送电子邮件通知，但没有人会在晚上检查，甚至在核心时段也需要时间来通知新邮件。像你这样的关键问题，需要有人立即得到通知。

像 [PagerDuty](https://www.pagerduty.com/) 和 [VictorOps](https://victorops.com/) 这样的服务已经使得这样做变得微不足道。正如预期的那样，DataDog 与这两者进行了本机集成。这两种服务都支持具有升级策略的随叫随到轮换计划，呼叫电话、短信、电子邮件等等。

### 生产故障排除

所以你已经被警告了，需要迅速弄清楚发生了什么，该怎么办。您的下一站通常是日志，但是一次查看一个服务器的日志文件肯定会浪费很多时间。

随着时间的推移，日志管理工具和服务已经成熟，Splunk 有很好的替代产品。 [Loggly](https://www.loggly.com/) 和 [LogEntries](https://logentries.com/) 不仅仅涵盖了基础知识，还提供了索引和搜索功能、日志事件的图形化、对 JSON 的理解，以及与几乎所有日志框架的现成集成。它们的核心是提供了一种快速查看所有日志的方法，而不必去单独的服务器。此外，当指标关闭时，您可以监视日志记录 à la DataDog 和警报(通过 VictorOps 或 PagerDuty)的各个方面。

上面的方法已经解决了大多数需求，但是我想触及一个更高级的问题，特别是对于微服务架构。当涉及多个服务时，在入口点找到故障是容易的，但是在处理用户请求时找出调用链中哪个后端服务失败了可能是相当困难的。

我称之为日志拼接的架构模式解决了这个问题。通过日志拼接，您可以针对给定的用户请求获取整个架构中的所有日志。这允许您重新构建完整的调用链，并快速找到失败的根本原因。从概念上讲，这种技术很简单:在入口点生成一个惟一的请求 ID，将它传递给每个调用，并记录下来。现在，您可以通过搜索该请求 ID 来调出所有日志。实际上，这可能会变得复杂，因为您需要:a)确保所有调用的一致性，b)考虑包括批处理作业在内的所有入口点，以及 c)在多线程服务中内部保存请求 ID。

我从一开始就不推荐原木拼接；然而，随着系统的成熟，这肯定是需要考虑的事情。如果你走的是微服务之路，这真的是必须的，因为随着服务数量的增长，跟踪调用链变得越来越困难。

## 把所有的放在一起

将所有这些放在一起并没有太多的开发工作，但是你仍然需要投入一些时间。我想强调在迭代中工作的重要性。设置一到三个闹钟，将你的数据狗连接到 VictorOps 或 PageDuty，研究几周，然后继续前进。请记住，你不会一开始就做对；你的阈值会关闭，你会曲解或误解系统的行为。

操作模式分析不是微不足道的，但是不要花太多时间预先分析所有的东西。配置一些警报，让他们出来，边走边学习和调整。当你发现一个错误的警报响起时，花些时间去理解为什么。具体来说，你需要专注于为什么你认为这是正确的闹钟设置，而不是为什么你现在知道它不是。如果你采用这种系统化的方法，你会学得很快。

正如我上面提到的，配置 Loggly 或 LogEntries 非常简单，您应该马上这样做。然而，日志拼接是一项需要计划的复杂工作。由于其性质，它只有在被您的所有或大多数系统采用时才变得有用。因此，您应该只在您觉得有必要的时候，并且当您从您的开发组织的其余部分得到认可的时候，才开始它。

## 下一步是什么？

第 3 部分将涵盖持续集成和持续交付的主题，将它们分解成多个复杂的阶段，这样您可以从成本/收益的角度挑选对您最有意义的。