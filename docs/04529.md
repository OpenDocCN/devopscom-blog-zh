# 为什么要重新发明重复数据删除？云存储不便宜吗？

> 原文:[https://devo PS . com/reinvent-重复数据删除-非-云存储-廉价/](https://devops.com/reinvent-deduplication-isnt-cloud-storage-cheap/)

大多数人认为云存储比内部存储便宜。毕竟，他们为什么不呢？根据您的性能和访问要求，您可以以每年每 TB 276 美元或更低的价格租用对象存储。据 Gartner 和 ESG 的分析师称，企业存储每年每 TB 的成本在 2，500 美元到 4，000 美元之间。

这种比较对于主数据是有意义的，但是当您在云中出于其他原因备份或复制数据时会发生什么呢？想象一下，一家企业需要将 100TB 数据集的每月备份保留三年。在云中，这很容易等同于 3.6PB 的原始备份数据，或者每月超过 83，000 美元的账单。这相当于每年 100 万美元，甚至还不包括数据访问或检索费用。

这正是高效的重复数据删除对于内部存储和云存储都非常重要的原因，尤其是当企业希望将其辅助数据(备份、归档、长期保留)保留数周、数月或数年时。云存储成本可能会迅速增加，甚至会让精明的 IT 专业人员感到惊讶，特别是当数据量随着 web 级体系结构变得更大时——数据被复制，他们发现无法在云中消除重复数据。

## 云存储的承诺:便宜、可扩展、永远可用

云存储被认为是廉价、可靠和无限可扩展的——这通常是正确的。像 AWS S3 这样的对象存储，标准层的价格仅为每月 23 美元/TB，非频繁访问层的价格为 12.50 美元/TB。许多现代应用程序可以利用对象存储。云提供商提供自己的文件或数据块选项，如 AWS EBS(弹性数据块存储),起价为每月 100 美元/TB，按小时按比例分摊。也存在将传统文件或块存储作为后端连接到对象存储的第三方解决方案。

即使是每年 1，200 美元/TB 的 AWS EBS，也比成本高 2 到 3 倍且需要高额前期资本支出的本地解决方案更具优势。概括来说，企业被云所吸引，因为 OPEX 成本显著降低，前期成本极低，并且您可以按需购买(与传统存储相比，您必须在实际需求之前购买)。

## 副本，到处都是副本:云存储成本如何飙升

云存储和传统本地存储之间的直接成本比较可能会分散管理云中存储成本的注意力，特别是当越来越多的数据和应用程序迁移到云中时。云存储成本有三个组成部分需要考虑:

*   在对象或块存储上存储主数据的成本
*   数据的任何副本、快照、备份或归档副本的成本
*   数据传输费用。

我们已经讨论了第一个问题。让我们看看另外两个。

**数据的副本。**不是你往云端放了多少数据；上传数据是免费的，存储一份拷贝也很便宜。如果不小心，当您开始制作数据的多个副本(出于备份、归档或任何其他原因)时，成本会急剧上升。即使您没有制作数据的实际副本，应用程序或数据库通常也有内置的数据冗余并复制数据(或者用数据库的说法，复制因素)。

在云中，你对一个对象的每一次复制都会产生与原始对象相同的成本。云提供商可能会在幕后进行一些重复数据删除或压缩，但这通常不会返还给客户。例如，在 DropBox 这样的消费者云存储服务中，如果您为一个文件制作了一份或 10 份副本，则每份副本都将计入您的存储配额。

对于企业来说，这意味着数据快照、备份和归档数据都会产生额外的成本。例如，AWS EBS 存储快照每月收费 0.05 美元/GB。虽然快照经过压缩，仅存储增量数据，但不会进行重复数据消除。存储 100TB 数据集的快照每年可能要花费 60，000 美元，这还是假设它根本不会增长。

**数据访问。**公共云提供商通常对云区域之间或云外的数据传输收费。例如，在亚马逊地区之间移动或复制一 TB 的 AWS S3 数据需要 20 美元，而将一 TB 的数据传输到互联网上需要 90 美元。加上 GET、PUT、POST、LIST 和 DELETE 请求费用，数据访问成本真的会增加。

## 为什么云中的重复数据删除很重要

云应用程序按照设计是分布式的，并且作为标准部署在非关系型大规模可伸缩数据库上。在非关系数据库中，大多数数据在您创建副本之前就是冗余的。有一些常见的块、对象和数据库，如 MongoDB 或 Cassandra，它们的复制因子(RF)为 3，以确保分布式集群中的数据完整性，因此您从三个副本开始。

备份或辅助副本通常通过快照创建和维护(例如，使用前面提到的 EBS 快照)。数据库架构意味着，当您拍摄快照时，您实际上制作了数据的三个副本。如果没有任何重复数据消除，这将变得非常昂贵。[而现有的解决方案，专为本地传统存储设计，帮不了](http://datos.io/protecting-data-public-hybrid-cloud/)。

## 不仅仅是重复数据删除，还有语义重复数据删除

大多数重复数据消除技术在存储层工作，对数据块进行重复数据消除。这在集中式 SAN 或 NAS 存储上效率很高，但如果数据层是从存储中抽象出来的，就不行了——就像在 MongoDB 这样的分布式数据库中一样。这个世界上的重复数据删除需要解决两个基本问题:

*   它必须工作在数据层，而不是存储层。要从分布式集群中删除重复数据，软件必须理解并解释底层数据结构。
*   它必须在将数据写入数据库之前消除冗余数据。数据写入后，会在群集内进行复制，因此需要动态消除重复数据。

好消息是,[语义重复数据删除技术](http://datos.io/resource/semantic-deduplication-distributed-databases/)可以有效地与分布式云应用程序配合使用，帮助 MongoDB 和 Cassandra 等数据库削减高达 80%的存储成本。

— [沙拉布·戈亚尔](https://devops.com/author/sgoyal/)