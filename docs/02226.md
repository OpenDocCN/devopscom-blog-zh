# 确保您的人工智能为您的数据团队服务

> 原文:[https://devo PS . com/assure-your-ai-is-work-for-your-data-team/](https://devops.com/ensure-your-ai-is-working-for-your-data-team/)

人工智能工具为数据操作带来了巨大的希望。他们可以帮助团队确定要迁移的最佳应用，确定[最佳云基础设施](https://resources.unraveldata.com/blog/data-operations-re-imagined-unravel-introduces-the-first-ai-powered-dataops-solution-for-the-cloud)，甚至验证决策。但是，一个 IT 团队如何确保它使用的人工智能工具确实在推进它的[数据操作](https://devops.com/the-taxonomy-of-dataops/)目标呢？

一个难以下咽的难题是，即使是设计最好的算法决策和人工智能工具也容易出错。幸运的是，这与软件开发中的错误不同，软件开发中的错误很大程度上是由开发引起的。人工智能错误源于定义不明确的项目目标，以及组织倾向于将技术视为魔术。如果没有坚实的需求、模型监控和与现实的定期检入，AI 几乎不可能交付。

这就是为什么在引入任何会极大影响商业决策的人工智能工具时，审计[必须是一项指令](https://hbr.org/2018/11/why-we-need-to-audit-algorithms)。但是，在进行审核之前，请确保满足以下几点:

### 确保人工智能工具是“可审计的”

这一步确保组织将正确的人工智能工具带入他们的武器库。

人工智能工具在以下情况下是可审计的:

*   **透明:**当人工智能工具被用来增强企业做出的决策时，利益相关者必须能够窥视系统，以确保算法决策的合法性。确保你选择的人工智能工具有一个日志记录系统，它可以透明地显示系统如何做出决定，哪些因素对其影响最大，以及它对该决定有多大信心。这可以让决策者信任系统，并为开发人员创建一个反馈回路，以获取真实世界的数据，并根据您的需求增强和微调系统。
*   **采用最佳实践构建:**正如安全工程师在保护网络时遵循最佳实践一样，采用最佳实践构建的人工智能模型和工具在使用时会表现得更好。根据一般经验，所有人工智能模型都必须保留详细的访问和进程日志，纳入故障恢复机制，并生成定期健康报告。

### 树立成功的标志

不要把人工智能审计当成一个沙盒问题。如果团队清楚人工智能工具必须实现什么以及如何衡量它的成功，只有这样审计才能判断工具的性能。

建立描述成功的标志是有帮助的。这可能是人工智能模型正确预测的案例数量、花费的时间、它能够处理的边缘案例数量以及人工智能决策与人类决策冲突的次数。

## **审计**

一旦 AI 工具被集成到组织中，并在规定的时间内被积极使用，就必须进行审核。它们帮助您回答以下问题:

*   算法对最终用户来说是透明的吗？
*   它有可能被社会接受的方式使用吗？
*   它会不会产生不良的心理影响，或者无意中利用了人类天生的弱点？
*   该算法是否被用于欺骗性目的？
*   其设计是否有内部偏见或不称职的证据？
*   它是否充分报告了它是如何得出建议的，并表明了它的信心水平？

*[(HBR:《我们为什么需要审计算法》)](https://hbr.org/2018/11/why-we-need-to-audit-algorithms)*

### **评估算法对其用途的适用性**

**从用例的角度来看，现代软件应用中的人工智能算法往往分为两大类。一个是提供帮助人类做出决策的见解——这就是人工智能驱动的分析的全部内容。另一种是允许软件应用程序完全独立地执行自动化操作，就像 AIOps 工具越来越多地做的那样。**

**审计你的算法的一个基本步骤是确定它应该支持哪种类型的用例，然后评估它实现的有多好。定期这样做很重要，因为人工智能用例会随着应用程序的发展而漂移，算法的最初目的可能会随着时间的推移而改变。(通常，算法最初是作为提供见解的一种方式来实现的，但应用程序的更新期望算法能够支持自动决策。)**

### **比较和对比算法决策和人类决策**

**虽然人工智能模型的一些内部工作对数据科学家来说是一个黑匣子，但这些内部工作的结果却不是。人工智能审计必须建立一个过程和团队，定期并积极地监控人工智能做出的决策，并将它们与人类做出的决策进行比较。**

**这有助于在早期识别人工智能工具是否有[内在化的偏差](https://www.techrepublic.com/article/the-10-biggest-ai-failures-of-2017/)。有了 AI 系统，输入很大程度上影响了学习。例如，如果一个用于预测采购订单的工具在销售旺季被组织采用，该工具将假设这是组织的基准绩效。从长远来看，这会导致不稳定的预测。**

### **积极的实验**

**虽然审计应该发现人工智能工具的任何缺陷、偏见或安全问题，但它也可以用于测试系统变量。人工智能工具通常建立在对问题边界和趋势的假设之上。然而，假设在现实中是非常脆弱的。现实的基线可能会改变，导致人工智能产生可疑的结果。**

**审计还必须能够每年或每半年用新的假设重新审视人工智能工具，以发现任何有助于提高工具准确性的新参数。**

### **采访系统用户**

**最终，一个人工智能工具被投入使用，以减少或增加人类的工作量。日常用户不仅对该工具的工作原理，而且对其局限性和怪癖都有丰富的知识和见解。**

## ****结论****

**更常见的是，人工智能模型的神秘性被用作不稳定结果和糟糕表现的借口。通过建立一个强大而透明的审计系统，你的组织可以确保你的人工智能工具实际上为你的团队工作——如果没有，它至少可以发现罕见的场景和边缘情况，并帮助减轻它们。**

***本文由[代表](https://unraveldata.com/)撰写。***

**— [斯瓦蒂·卡卡拉](https://devops.com/author/swaathi-kakarla/)**