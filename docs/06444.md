# 如何最小化延迟及其对 UX 的影响

> 原文:[https://devo PS . com/how-to-minimize-latency-and-its-impact-on-UX/](https://devops.com/how-to-minimize-latency-and-its-impact-on-ux/)

***延迟会对用户体验产生巨大影响。在延迟影响您的客户体验之前，您需要了解以下信息***

几十年来，企业一直在进行数字化，但最近的事件加速了这一进程，超出了所有人的预期。客户现在使用的数字服务比以往任何时候都多，而且他们的转换成本通常非常低。这给企业带来了巨大的压力，不仅要提供在线服务，还要提供持续的高性能。曾经以秒为单位衡量性能的企业现在可以精确到毫秒甚至微秒。因此，他们渴望最大限度地减少延迟及其对利润的影响。

等待时间可以定义为在数据传输指令之后开始数据传输之前的延迟。无论我们如何定义它，它的影响是显而易见的:亚马逊的 [的一项](https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales/)[研究发现，100 毫秒(ms)的延迟耗费了 1%的销售额。谷歌的一项类似研究发现，搜索结果返回延迟半秒(500 毫秒)会减少 20%的流量。Loadstorm](https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales/) 的一项[研究显示，延迟对任何业务的转换率都有类似的影响。长时间的延迟会导致放弃购物车，沮丧的用户会离开你的网站去别处寻找同样的信息、产品或服务。](http://loadstorm.com/2014/04/infographic-web-performance-impacts-conversion-rates/)

寓意:当企业试图转换用户，并通过他们的管道移动他们时，延迟可能是最大的敌人。但是你如何衡量它，你能做些什么呢？

## **测量延迟**

考虑到延迟对用户体验的影响，令人惊讶的是许多企业没有给予足够的重视，甚至没有正确地衡量它。一个常见的错误是关注*平均*性能，这最终是一个理论测量，可能无法反映实际的最终用户体验。

一种更好、更有意义的测量真实世界延迟的方法是使用百分位数。

潜伏期通常以第 50、90、95 和 99 个百分点计算，通常称为 p50、p90、p95 和 p99。想象一下 10 次延迟测量:1、2、5、5、18、25、33、36、122 和 1000 毫秒(ms)。p50 测量值代表系统的*中值*性能。在这种情况下，p50 测量值为 18 毫秒，这意味着 50%的用户经历了该延迟或更少。p90 测量值为 122，这意味着 10 个延迟中有 9 个测量值小于 122。

给定百分比内的每个测量值都反映了实际影响至少一个(但可能更多)最终用户体验的真实延迟。

相比之下，我们 10 次测量的平均值约为 125 毫秒，甚至不接近观测数据的中点——事实上，略高于第 90 百分位。

重要的是要记住异常值，也就是所谓的“长尾延迟”在现实条件下，p99(以及更高)的延迟通常是您最需要担心的。

Azul Systems 的 Gil Tene 在他的演讲“[如何不测量延迟](https://www.youtube.com/watch?v=lJ8ydIuPFeU)”中解决了这个问题他指出，p99 的延迟很容易影响远远超过预期比例的用户。如果一个典型的用户会话包含五次页面加载，平均每页 40 个资源，那么大约 18%的用户至少会经历一次比 p99.9 更长的响应。他还指出，超过 95%的用户经历的平均响应百分比将是 p99.97 延迟。

正如谷歌工程师路易斯·安德烈·巴罗佐所说:

> *“当一个请求由并行完成的工作实现时，正如当今面向服务的系统中常见的那样，总体响应时间由并行操作的长尾分布决定。每个响应都必须具有一致的低延迟，否则整体操作响应时间将会非常慢。”*

换句话说，一组并行操作中最慢的操作通常定义了用户体验。如果其他 1%的操作阻碍了一切，那么 99%的操作很快完成也没关系。这解释了为什么它不足以保持 p95 的潜伏期极快。你还必须保持长尾延迟(p99 及以上)始终较低。

## 长尾延迟的原因

要解决长尾延迟的问题，我们需要了解它为什么会出现。长尾延迟有许多原因，但是，重要的是，它通常不是由特定于应用程序的问题或正常的网络延迟引起的。相反，长尾延迟有系统性的原因，通常与底层基础设施的问题有关。这些可能包括由于 Java 虚拟机(JVM)“垃圾收集”、上下文切换、数据库修复、缓存刷新等造成的暂停。这使得长尾延迟很难诊断和修复，因为这通常是一种“打地鼠”式的练习。

### **磁盘 I/O 和网络瓶颈**

长尾延迟的主要原因是网络和系统瓶颈。它通常大量投资于可用的最佳组件:出色的固态硬盘(SSD 和相关 NVMes)、CPU 和内存。但它经常通过配置“狭窄”的网络来限制所有高性能硬件，从而搬起石头砸自己的脚。

SSD 设置也经常配置错误。云固态硬盘有两个关联的节流:突发和持续。诸如流和压缩之类的后台操作会耗尽持续的吞吐量，该吞吐量可能是突发的 1/10。当后端进程占用大量 I/O 时，就没有容量留给前端用户引发的操作了。虽然一些事务将能够使用突发容量，但稳态前端流量将开始积压并最终超时。

### 速度不匹配

一方面，CPU 和内存的组合速度以及另一方面，磁盘速度对数据库性能有很大影响。CPU 往往更快，而磁盘往往更慢。固态硬盘正在赶上 CPU，但这一规律仍然普遍适用。

速度不匹配是受磁盘速度限制的写工作负载的一个更常见的问题。这可能是因为磁盘速度慢或者负载大。大型有效负载将瓶颈转移到磁盘。当需要写入磁盘时，任何相对缓慢的磁盘速度都会导致查询在缓冲区中备份。这将导致异常 p99 延迟。

### 超出您的延迟预算

每个系统都设计有“延迟”预算，即延迟与吞吐量的比率。p95 和 p99 延迟是给定系统设计支持的吞吐量的函数。你可以把这个高速公路交通量和吞吐量的比率想象成高速公路上的车道数。更多的车道意味着高速公路可以承载更多的车辆，从而承载更多的出行。这就是吞吐量。延迟是由速度限制定义的。拥有多条车道和缓慢的最高速度可以减少总的出行次数。两者之间的比率定义了延迟预算。

理想情况下，如果您只是增加更多的吞吐量，您应该能够减少延迟，对吗？嗯，不一定。就像高速公路上的交通可以扩大到填满一条额外的车道，仍然让你陷入交通堵塞，你可以很容易地压倒那些一开始就没有设计好的系统，即使你试图增加更多的吞吐量。事实上，试图增加更多的吞吐量会降低所有的延迟。在路由世界中，这种糟糕的架构考虑被称为 [bufferbloat](http://www.enterprisenetworkingplanet.com/netsp/article.php/3926076/Bufferbloat-Sacrificing-Latency-for-Throughput.htm) 。

如果一个系统试图增加过多的吞吐量，而系统中仍然存在其他瓶颈，那么您最终只会有更长的延迟，甚至到事务超时的时候。这可能会加剧糟糕的情况，因为所有失败的事务都将尝试一次或多次重试。

处理大数据的系统有几个考虑因素。其中包括最明显的硬件导向因素；存储(例如，NVMe 固态硬盘目前广泛流行的原因)、CPU 内核、内存(RAM)和网络接口。

运行在英特尔至强可扩展处理器白金芯片上的现代服务器在 AWS、Azure 和谷歌云上很常见。服务器需求取决于每个多核芯片能够支持的吞吐量。

其他考虑事项包括:如何设计您的数据库系统来处理数据分发和复制以实现高可用性，对等设计与领导者/追随者设计，如何最大限度地减少服务器之间的跳跃和重定向，有效利用缓存，如何有效利用所有可用的硬件，等等。

这些都是定义系统延迟预算的组成部分。理解并保持在这些限制范围内是很重要的。当超过这些值时，实际上肯定会出现异常值延迟。

## **延迟和数据库**

到目前为止，我们将长尾延迟视为一种系统范围的现象。现在让我们考虑一下数据库的作用。大多数 HTTP 和 API 请求都会导致至少一次(如果不是更多的话)数据库调用，通常是读和写的混合。因此，数据库在终端用户的延迟体验中起着核心作用。

NoSQL 数据库是专门为满足低延迟、全球分布式数据存储的需求而发明的。NoSQL 数据库的基本前提是能够在廉价的商用硬件上“向外扩展”。当需要更多容量时，管理员只需将服务器添加到数据库集群中。然而，这种简单性已经演变成了一种弱点。集群的增长经常失控，导致一种称为“节点蔓延”的现象第一代 NoSQL 数据库的体系结构积极鼓励较大的功能较弱的机器集群。从延迟的角度来看，这种架构实际上确保了不一致的 p99 性能，因为更多的节点间流量、上下文切换、磁盘故障和网络中断，所有这些都会产生延迟异常值。

对这个问题特别敏感的一个数据库是 Apache Cassandra。首先，Cassandra 是用 Java 实现的，容易受到垃圾收集(GC)引起的暂停的影响。一些监控团队甚至有专门的指标来衡量 GC 停滞百分比。压缩和修复操作在大型集群中变得更加繁重，增加了困扰 Cassandra 部署的异常值。

其次，Cassandra 利用现代硬件进行压缩和流式传输的能力有限。由于 Cassandra 是一个“只附加”的系统，保持读取数据的一致性需要一个压缩过程。具有大量内核的服务器在公共云、IaaS 和内部部署中随时可用。然而，Cassandra 无法随着可用内核数量的增加而线性扩展压缩，因此它无法有效地利用那些较大的服务器。由于需要在集群中部署更多更小的服务器，这一限制导致了更高的读取延迟。

由于 Cassandra 公开了存储介质、JVM 堆缓存和读写并发性的设置，因此为特定工作负载正确配置系统的任务就落在了管理员身上。当工作负载不可预测且出现峰值时，管理员必须不断调整 Cassandra 集群，以优化读写延迟。

许多 IT 组织转向外部缓存，以帮助最终用户免受其数据库较差的长尾性能的影响。缓存通常用于增强读取性能，但写入延迟带来的好处很少或没有。依赖于实时性能的事务系统不能丢弃突变，所以缓存没有任何帮助。事务性系统依赖于写和读的低长尾延迟。如果峰值太频繁，客户端体验就会恶化，变得非常缓慢。

尽管如此，读取的前端缓存通常是一种必要的罪恶，以至于它被视为必须的。然而，保持缓存和持久存储之间的一致性是一个有据可查的难题，很容易使运营陷入困境，并对客户产生负面影响。最佳方法是确定一个系统，该系统以优化性能和数据完整性的方式内在地结合了高速缓存和持久存储。

## **赢得持续低长尾延迟之战**

考虑到这些问题，您的组织可以遵循一些准则来最小化长尾延迟。

*   根据贵组织当前和未来的吞吐量目标，设计确保最低 p99 延迟的系统。
*   不要忽略性能异常值。拥抱它们并利用它们来优化系统性能。
*   减少体系结构中的组件数量，从冗余缓存系统到臃肿的硬件基础架构。通过在更强大的硬件上垂直扩展来缩小数据库集群。
*   采用随资源线性扩展的数据库基础架构:CPU、内存、存储、网络和群集中的节点数量。
*   当使用数据库即服务(DBaaS)产品时，要注意“扩展失误”——在这种情况下，您无法进行线性扩展，并且必须增加支出，以超出您从系统中获得的边际收益。
*   确保您的 DBaaS 供应商可以提供多区域部署，以便您可以在应用程序附近利用该产品，从而消除长距离数据流量。虽然这不会减少数据库内的延迟，但会减少数据库和客户端应用程序之间的端到端数据库延迟。

延迟在 IT 计算中经常受到冷落，因为对它的理解和衡量都很糟糕。但是你不能忽视它。不管你是否认识到它，它都会造成伤害(你越不认识它，它造成的伤害就越大)。幸运的是，正如我们所看到的，有很好的方法来测量延迟并将其压缩。有了正确的指标和明智的策略，企业可以将过去令人生畏的对手转变为客户体验优势。