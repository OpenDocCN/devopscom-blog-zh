# 消除技术招聘中的无意识偏见

> 原文：<https://devops.com/eliminating-unconscious-bias-in-tech-recruitment/>

***为了让员工队伍更加多样化，企业需要意识到招聘中无意识偏见的作用，并采取必要措施尽可能消除这种偏见***

多元化组织的商业案例很清楚:一个更加多元化和包容的企业总是能带来更好的结果。从法律角度来看，随着各种歧视立法早已通过，雇用一支更能反映整个社会的劳动力不应有任何障碍。

那么，为什么我们会不断地看到数据和听到经验，而在所有部门，情况却并非如此呢？是什么阻碍了组织内部多元化的加速？

一个问题是招聘中无意识偏见的作用。我们都有偏见，这是由我们个人对复杂的文化、社会和经济经历的反应形成的。挑战在于这些偏见如何影响我们个人和职业生活中的决策。它们对我们的行动有直接影响，并且从业务角度来看，会产生重大后果。

在技术上，这可能导致我们的偏见被编程为旨在帮助但最终阻碍社会不同部分的解决方案。已经有无数的例子表明，人类的偏见被有意或无意地编入了人工智能工具，然后这些工具做出的决定会对社会的某些部分产生不成比例的影响。

当一个组织没有足够多样化的员工时，这种情况就会发生，这种员工有权挑战决策，并强调产品可能具有偏见或偏好。

这就是为什么正确的招聘如此重要，然而正如之前强调的那样，无意识的偏见也会产生影响。这意味着，即使面对两个技能、经验和资历完全相同的候选人，招聘经理也更有可能选择与他们的偏见一致的人。这影响了所有的职业——耶鲁大学的一项研究发现,“男性和女性科学教师都更有可能雇用男性，在能力上给他更高的排名，并且愿意比女性多付他 4000 美元。他们也更愿意为男性候选人提供指导，而不是女性候选人。

因此，我们如何根除招聘中的无意识偏见，并确保它不会阻碍创造更具包容性的技术劳动力的动力？

首先，重要的是要认识到你从哪里招聘和你如何招聘同样重要。如果你只从相同的学校或相同的网站招聘，那么你将任由这些机构的多样性摆布。如果你只使用一种途径来申请，无论是只使用招聘顾问还是使用一个只能通过电脑访问的网站，那么你又一次把自己限制在了有这些途径的候选人身上。

除了重新考虑人才库之外，减少无意识偏见的一个方法是通过去除识别特征——没有照片，没有名字，出生日期或学校和大学成绩。这在一定程度上可以有所帮助，因为决策者必须脱离候选人的经验以及他们如何展示自己以前的角色，但这也有其局限性——例如，对于入门级职位，相关经验可能有限。

这是一个快速解决方案。对于一个更可持续、彻底和长期的方法，招聘人员——特别是那些招聘技术职位的人——需要考虑他们如何准确判断技能组合。这本身就具有挑战性—在较大的组织中，那些参与早期阶段选择的人可能没有必要的背景知识来做出正确的选择。

这就是为什么拥有一个匿名、客观的环境来评估技能可能是答案。使用与成功的申请人非常相似的编码测试将使组织能够评估候选人，并提供他们是否适合该职位的明确评估。然后，这可以与其他考察能力和文化属性的测试一起使用，对候选人的适合性进行评分。

正是这种匿名和关注技能的结合有助于消除无意识的偏见；[一项研究发现，](https://phys.org/news/2017-05-gender-bias-open-source.html)如果一个为开源软件社区做出贡献的女性身份不明，她们的贡献可能比男性更容易被接受。当一个女人的性别是可识别的，他们更容易被拒绝。这一信息很明确，也适用于技术招聘:把注意力从谁在做这项工作上移开，让工作成为焦点，你会看到一个更加多样化的劳动力出现(假设申请人群体一开始就是多样化的)。

我们需要多样化的员工基础；这是我们能够确保正在开发的工具和技术将有助于社会而不是增加不平等的唯一途径。要做到这一点，企业需要意识到无意识偏见在招聘中的作用，并采取必要措施尽可能消除这种偏见。这意味着匿名——但更重要的是，这意味着专注于做相关工作的技能和能力。