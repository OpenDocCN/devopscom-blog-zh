# 自动调整规模是神奇的想法

> 原文:[https://devo PS . com/automatic-right-sizing-is-magic-thinking/](https://devops.com/automatic-right-sizing-is-magical-thinking/)

几个月前，AWS 布道者 Corey Quinn 写了一篇名为“[正确确定实例大小是没有意义的](https://www.lastweekinaws.com/blog/right-sizing-your-instances-is-nonsense/)”的短文。像往常一样，科里在他的降低成本-魔术-人工智能行业炒作上是一针见血的。但是他的作品只是触及了表面。我会把这个论点更进一步，说任何告诉你他们可以自动地和一般地“适当地调整”计算实例的人根本不理解软件是如何工作的。

你不觉得这太咄咄逼人了吗？和我在一起。即使您最终不同意，也可以从“自动调整实例大小”的讨论中学到很多关于 AIOps 的知识。

## 什么是合适的规模？

直接引用声称为云实例提供“适当规模”的众多服务之一的网站:

“建议引擎利用您的资源的相关利用率度量的时间序列数据，然后围绕平均和峰值利用率时段创建统计模型。该工具利用历史利用率数据来识别跨实例类型、系列和区域的性能特征，从而为您的工作负载提供有效的建议。”

这种“规模适当”背后的想法非常简单:跟踪一系列云服务指标(如果可用，也可能是一系列操作系统指标)，使用一些统计模型(在 VC 平台上通常称为“AI ”),并神奇地提供更具成本效益的云实例类型的建议。

只有一个问题:从通用度量标准中创建一个有用的统计模型实际上是不可能的，除非你的软件是专门为支持它而构建的，而这是软件设计的目标。事实上，软件几乎总是以完全违背这一目标的方式构建的，而且理由非常充分。要了解原因，让我们回顾一下“合理调整规模”背后的假设:

1.  该软件将能够使用所有给定的资源
2.  随着资源的增加，性能将可预测地提高(或降低)
3.  指标准确描述了应用程序负载
4.  缩放尺寸是独立的
5.  对连接的系统没有副作用

事实证明，这些支持合理规模的假设通常都不成立。

## 软件扩展速成班

理论上，软件是资源瓶颈，无论是 CPU，磁盘，内存，网络，你有什么。然而，在实践中，构建能够充分利用资源的软件是极其困难的。

描述软件如何随资源或负载扩展的一般曲线被称为[通用可扩展性法则](http://www.perfdynamics.com/Manifesto/USLscalability.html) (USL)。简而言之，它说，在任何显示规模与性能的图表上，您都会看到一个线性扩展的区域，其中增加资源(比如说 CPU 核心)会成比例地提高性能；然而，您将看到性能在非线性的基础上不断提高，每增加一项资源，收益就越来越小，直到某一点，收益变得微不足道，完全可以忽略不计。这就是所谓的[阿姆达尔定律](https://en.wikipedia.org/wiki/Amdahl%27s_law)，它指出每个程序的性能都受到串行部分的限制。

除了阿姆达尔之外，还有逆行缩放的问题，人们常常忘记逆行缩放的存在，直到后果迎面而来。在这个问题上，增加资源实际上会减慢系统的速度。没错。从这一点开始，更大的服务器会使你的软件运行更慢。

发生这种情况的原因是，为了线性扩展，工作负载和资源必须完全隔离和相互解耦，这在现实中是不可能的。总是有共享的组件，例如内核调度程序、内存控制器、主 PCI 总线，也许算法需要锁定。在任何情况下，最终结果都是在共享资源上排队，这在过载时也可能成为瓶颈。想象一个超市收银台:你可以让越来越多的购物者进入商店，但最终他们还是会在收银台前等待，不管你开了多少收银台，配备了多少工作人员。业绩受到收银台数量的限制，而不是受到购物者或店员数量的限制。更糟糕的是，如果队列失去控制(也许人们厌倦了等待，购物车被遗弃在剩下的购物者面前，堵塞了结账的道路——可以认为这是重试和超时的争用)，结账的吞吐量将会下降，因为柜台对购物者来说是饥饿的。

![right-sizing](../Images/42413129dc31cd1ab996f96eb582f97b.png)

USL 向我们展示了当我们扩展时吞吐量会发生什么变化，但是延迟呢？

![right-sizing](../Images/616f24f047356a944d3b08577d2b524e.png)

当资源利用率接近 100%时，资源的等待时间将以非线性方式接近无穷大。这就是系统被设计成在低利用率下运行的原因，这样服务质量就不会下降太多。您可能会看到一台服务器以 50%的利用率运行，并想，“我们可以使用一半资源的服务器，这样可以省钱！”但是，如果您真的尝试这样做，您会将延迟和服务质量降低到一个不可接受的水平，很可能导致中断。

## 配置的黑暗艺术

即使您的软件在理论上能够利用可用的资源，它也需要正确配置才能使用它们。缓冲区大小、线程池大小、内存堆大小、连接数——大多数软件都有许多选项来针对资源和特定工作负载进行调整。你不能只改变盒子的大小就指望它能工作！更不用说，很有可能你目前的配置远非最佳。我通过进行一行配置更改，多次大幅减小了集群的大小。

例如，常见的 web 服务器配置是服务器可以处理的并发请求数(通常表示为线程数)，它与可用的 CPU 内核数、特定工作负载可用的内存量以及处理请求所需的平均时间有关。你要解决的问题不是“什么样的实例规模会有最好的投资回报？”而是“什么样的实例规模和配置组合会有最好的投资回报？”这是一个完全不同的问题，需要应用程序的特定知识来回答。

## 让他们吃掉宝藏

在过去，当你试图分配超过当前可用的内存时，操作系统会简单地拒绝你的请求。啊，过去的美好时光很简单！唉，在我们寻求简化编程和资源管理，并允许软件有效地适应变化的环境的过程中，我们经常使用资源权衡。例如，一个复杂的计算可以使用 CPU 一次又一次地计算，或者可以保存并重用结果，从而节省 CPU 时间并换取 RAM 或磁盘的使用。这种模式很常见；当您过度分配内存时，操作系统可能会通过压缩内存对象来牺牲 CPU 以释放内存，也可能会通过将 RAM 换出到交换区来牺牲磁盘空间。Java、Node.js 和 Go 都有类似的权衡，它们将 CPU 时间花在垃圾收集上来释放 RAM。现代软件在多个维度上对 CPU、RAM、磁盘和网络进行了大量权衡。最终结果是不同的资源以许多意想不到的和模糊的方式结合在一起。

## 谎言，该死的谎言！(和指标)

说到以 50%的 CPU 利用率运行的服务器，很有可能在同一时间服务器的 CPU 也达到了极限。怎么会这样呢？这是因为你看到的指标不是原始数据，而是集合——在许多情况下，是平均值——而集合隐藏了某些可能非常重要的行为；例如，峰值和猝发，比如您从压缩、垃圾收集和现代软件中例行运行的其他周期性进程中获得的峰值和猝发。在现代服务器上，每秒钟有数十亿个事件发生，而每分钟发出的指标数据点却很少。所有指标都是亏损的；很简单的数学，真的。但是机器学习(ML)模型只和它们处理的数据一样好，所以如果这些指标不是专门为了显示相关行为而创建的——它们不是——这个模型将完全无视它们的存在。

## “性能”到底是什么？

每当我们处理资源分配时，我们感兴趣的是它对性能的影响，这提出了一个显而易见但相当不舒服的问题:您对“性能”的定义是什么是吞吐量吗？潜伏？平均值还是第 99 百分位？哪笔交易？或者，也许你最感兴趣的是在网站上执行的购买率？这些都是不同的东西，通常，优化一个可能会降低其他的。

这种讨论是任何性能工程会议的第一步——但完全不在“规模适当”的服务范围内，并且您最不希望看到的是耗费您资金的 ML 模型的一般成本函数。

如果所有的性能目标都可以一次实现，这并不算太糟糕，但是，不幸的是，其中一些目标是相反的:例如，由于排队效应，更高的吞吐量会导致更高的延迟。当对软件系统进行变更时，我们必须知道什么性能指标对我们来说是重要的。

## 局部优化的诅咒

将一个机器集群看作一个独立的系统是非常诱人的。但是如果那个系统正在做一些有意义的事情，它就是某个更大系统的一部分，改变配置很可能会对它所属的更大系统产生影响。当我们对子系统进行变更时，我们的目的是从整体上改善系统，让客户满意，赚更多的钱。但是，当一个子系统的变更是由降低子系统成本的愿望所驱动时，结果往往是系统总成本的增加！这是因为与整个系统的成本相比，子系统的局部成本相对较小，更不用说系统的收入可能减少。例如，您可以通过使用较旧、较慢的服务器来节省大量资金，但您的客户不会对缓慢的应用程序非常满意，您的利润也会受到影响—这可能会使您付出比您节省的更多的成本。

拿这个*来说荒谬的*，你可以通过完全关闭它来节省 100%的子系统成本。当然，假设改变服务器大小不会有任何副作用，正如所讨论的，这是极不可能的。联网系统也会有副作用，其中一些不会立即显现。负载是可变的，运营过度配置和缓冲区通常是有原因的。利用率低的原因很可能是安全边际。

## “规模合适”的问题

“合适的规模”的基本问题是一个相当明显但隐含的假设，即存在“合适的”规模。软件工程是关于权衡的，正是因为很少(如果发生的话)一件事情可以在不使另一件事情变得更糟的情况下得到改进。权衡意味着要做出商业决策，你真的不想让一个通用的 ML 启发式规则来为你做出这些决策。ML 非常擅长处理有大量数据可用的问题，这些数据是高质量的，这些数据是行为的预测性的(这对于复杂的系统来说不是这样！)最重要的是，这个问题被很好地定义了。AIOps 中的大多数问题远非如此。不要相信我，相信那些在高级运营和 ML 方面都表现出色的人。

即使使这样的 ML 模型工作是可行的，软件也不能自动适应不同的机器大小并充分利用服务器资源。如果是的话，像 ScyllaDB 和 Azul Systems 这样的公司就不需要存在了。在现代硬件上创建可扩展且资源高效的软件是一个非常困难的问题，如果没有这些构建模块，ML 模型正在构建非常不稳定的结构。

值得强调的是，我并不反对调整服务器的大小和配置，只是为了一些本地的"[成本节约](https://devops.com/?s=cloud+cost)"目标而自动盲目地这样做并不是您可能认为的解决方案。这种改变的目标应该是在系统如何工作的理论指导下，提高更大系统的整体质量和性能。ML 不是人类思维和学习的替代品。当然可能有一个“最优”的实例类型，或者甚至几个，但是“最优”意味着一个目标度量，当然不是成本降低。没有一个系统是以廉价为唯一目的的。所有系统的存在都是为了首先满足业务需求，其次才是低成本。