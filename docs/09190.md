# 安全软件峰会:安全领导者的可达性和风险

> 原文:[https://devo PS . com/secure-software-summit-可达性和安全风险-领导者/](https://devops.com/secure-software-summit-reachability-and-risk-for-security-leaders/)

如果不考虑任何潜在漏洞或安全缺陷中的两个关键因素:可达性和风险，就不可能管理[安全态势](https://devops.com/?s=security+posture)。这两个因素是相关的。可达性定义了检测到的给定安全漏洞(例如 CVE)实际上可以被攻击和利用来获得特权访问以及直接或间接访问关键系统或数据的程度。风险是一种业务度量，用于评估漏洞对企业或组织造成实际损害的可能性。一般来说，没有可达性，风险就小。

## 如何看待可达性

近年来，可达性和风险发生了巨大的变化，我们已经从一个硬边界“堡垒”式的安全方法转向更分布式的系统、API、云计算、SaaS 和更多潜在的攻击入口和出口点。为了减轻这种新的风险，我们实际上已经采取措施来加强所有新暴露的内部元素和关键的安全系统。我们围绕身份建立了一个新的边界，具有身份认证和零信任。我们围绕互联设备、云基础架构、虚拟化环境以及所有这些系统的配置构建了外围环境。在每一个有潜在风险的地方，你都需要考虑加强新的小型边界。

我们在风险和可达性方面投入较少的一个关键方面是人的方面。尽管人是最容易受到攻击的，但我们还不认为人是需要防御的边界。作为人，我们创造有缺陷的软件。我们错误地配置了我们的基础设施、安全工具和认证系统。可达性新思维的一个关键部分必须是更好地考虑和减轻人们的风险。这意味着通过更好的系统或更好的设计来简化他们的决策树，并帮助他们成为更好的灰质边界。

由于我们的 IT 和应用环境的原子化，以及随之而来的安全堡垒的小型化，我们创造了一个更加精细的表面。在某些情况下，比如通过细分，我们增强了安全性，降低了风险；在其他情况下，我们增加了复杂性。毫无疑问，我们现在有更多的接触点和更广泛的攻击面暴露在世人面前。在评估可达性时，一个关键的考虑因素是这些点中的每一个都可以被利用到什么程度，以及达到什么样的广度和深度——查看关键系统的水平遍历和即时危害，或者破坏供应链和其他关键子系统以进行后续攻击。微型堡垒心态是一个有用的框架，用于思考潜在的攻击面，并在正确的位置实施正确的控制，以解决可达性问题。

## 风险评分和可达性

那么，风险评分和可达性之间的相互作用是什么？如果我们的最终用户需要新技术，我们不能拒绝引入更多复杂性和潜在更多风险的新技术。我们需要更好地管理如何创建和应用风险评分，以帮助人们在这个更加复杂的环境中表现得更好。

如今，了解整体安全状况并在决策和判断中应用适当的环境的责任已经变得越来越广泛。部署、使用、构建或设计应用程序和技术环境的每个人都必须不断思考他们正在处理的任何项目或代码的安全含义。这些影响不仅体现在应用程序、系统或基础架构层面，还体现在企业的整体利益上。这意味着更广泛地理解由可达性和关键程度驱动的风险评分，并更好地考虑可达性和可攻击性的含义。

在网络安全中，不缺乏风险衡量。在评分过程中注入可达性是一种确定漏洞的方式，以确定这些问题中哪些可能是实际风险。可能存在包含重大业务风险但可达性非常低的情况，这可能导致安全团队以不同的方式处理该漏洞。

然而，总的来说，仅仅根据以编程方式生成的风险分值来做出决策是不够的。任何风险分数都反映了生成分数的系统，以及该系统是如何被供应商或您的团队调整的。务必记住，任何风险评分都包含一些主观判断。这是必要的，但也为漂移和偏差注入了机会，这可能会扭曲分数，使你更不安全。

明确地说，风险分值在应用安全中有着重要的作用。风险分值有助于您减少噪音，并在大量 CVE、漏洞和警报中找到信号。事实上，如今围绕安全性的噪音如此之多，以至于任何有效的团队都依赖于其决策链、优先级和策略工作中的多层降噪。风险评分失败的地方是无法准确映射到业务风险，或者不能准确反映任何 CVE 或其他报告问题的可达性。这要求安全团队构建自己的内部和心理风险模型，针对最关键的系统建立威胁模型，并创建可用于验证风险评分系统决策的上下文。如果人工代理能够快速判断任何给定漏洞的可达性和可攻击性，或者识别自动风险评分引擎何时可能无法准确反映业务风险，那么了解数据如何流经应用程序和基础架构是至关重要的。

实际上，有两个不同的过程在起作用:计算风险和考虑风险。计算风险是程序化和自动化的；最初是以人为导向的，但由针对安全测试工具(如软件组成分析、静态应用程序安全测试、模糊化和林挺)暴露的大量漏洞应用的模型驱动。考虑风险是一项更全面的工作，它利用了人类的直觉能力和由经验和来之不易的洞察力驱动的系统的先天知识。

思考将帮助安全团队识别未检测到的偏差，指导威胁建模以更好地考虑漂移，并突出显示人为故障可能以风险评分系统永远无法捕捉的方式增加风险的领域。最重要的是，沉思是关于背景的。一个人类演员有越多的背景知识，他们就能更好地理解大局。对大局了解越多，人们做出的决定就越好。这也必须贯穿并通知模型和风险评分引擎，以便在计算中捕捉到考虑的价值。

## 使用风险评分工具将可达性和可攻击性降至最低

安全团队必须不断衡量所有安全工具的效率和功效。一般规则是，随着时间的推移，安全控制会失去效力，因为供应商会失去重点，或者无法正确应对新出现的威胁类别。如果您有一个安全工具，它可以根据您的可达性准则生成风险分值，并且证明是准确的，那么您应该将该系统提升到更高的信任级别，并对其结果给予更多的权重。也就是说，即使产生风险的工具您认为是准确的并且表现良好，也必须不断地评估和交叉检查。

不幸的是，只需要很小的偏差就能让组织面临潜在的灾难性攻击。这种计算的一个关键部分是确保人类掌握风险分数是如何创建的，并继续影响分数以对抗漂移。漂移是自然的，但不是不可避免的。您的代码和环境在不断变化，这可能会导致可达性发生变化，从而对您的整体风险状况产生重大影响，并改变您应对不同系统和风险的方式。举一个例子，自动风险评分系统可能不理解新型供应链攻击可能导致对其他操作系统中类似组件的后续相关攻击。实际上，人类的智慧和思考是使风险评分工具更有价值和更可靠的秘密因素。

## 要点:原子化系统、可达性、风险和人类

随着我们进入边缘计算等新的基础设施模式，以及网络上的所有系统获得容量，环境和应用前景将继续进一步原子化。对于这种情况，安全团队和开发人员应该:

*   认识到我们已经从一个全球边界转变为一个原子化的小型边界群，并转变他们的思维模式，将安全性和在微观层面上建立堡垒视为降低可达性和风险的一个重要途径
*   开发人员和安全团队需要在可达性和风险的基础上评估他们构建和保护的系统，以正确地确定优先级。风险评分工具是减少噪音的有用元素，但不能取代人类智能来检查风险决策
*   在整个过程中，人类必须继续指导和告知这些风险评分系统，并确保风险评分不会成为关键程度和重要性的盲目代理。允许自动化风险评分主导决策过程会使安全漂移变得更加危险，并使人为错误得不到识别，从而使应用程序和基础架构既可到达又处于风险之中。

* * *

*本文由 RiskLens 首席技术官 Bryan Smith 和 ShiftLeft 产品营销总监 Rob Lundy 共同撰写。*

***关于安全软件峰会**  安全软件峰会汇聚了全球领先的安全软件开发创新者、从业者和学者，分享和传授安全编码和部署实践的最新方法和突破。如果您正在开发、发布和保护软件，快速交付新功能，并从一开始就构建东西，请单击下面的链接访问本次峰会的所有会议。*

[https://go.shiftleft.io/secure-software-summit-2022-replay](https://go.shiftleft.io/secure-software-summit-2022-replay)